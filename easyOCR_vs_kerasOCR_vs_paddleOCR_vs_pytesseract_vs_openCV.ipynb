{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPP8Q4kgSDbVLPAB8WH8Bpp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/likeshd/ocr_work/blob/main/easyOCR_vs_kerasOCR_vs_paddleOCR_vs_pytesseract_vs_openCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methodology\n",
        "Image Selection\n",
        "I have selected three images for comparison, each presenting unique challenges to the OCR tools. The images used are as follows:\n",
        "\n",
        "Image 1: A photograph of a car’s license plate. The text is clear and high-contrast, making it a relatively straightforward image for OCR. The background is metallic, and the text is well-defined, which should generally pose minimal difficulty for most OCR systems.\n",
        "Image 2: A cover page of a notebook with the word “Carousel” prominently displayed. This image includes stylized fonts and a patterned background, which adds complexity. The OCR tool must accurately detect the decorative text without being misled by the background patterns.\n",
        "Image 3: A picture of a broadband router with a label that includes text and a QR code. The text is relatively small and located on a plastic surface with some reflection, making it challenging for OCR systems to read without errors. The presence of the QR code could also add noise to the text detection process.\n",
        "These images were chosen to evaluate the OCR tools across a range of scenarios, from simple and clear text to more complex, stylized, or low-contrast situations.\n",
        "\n",
        "Criteria for Comparison\n",
        "I have considered following parameters in the comparison:\n",
        "\n",
        "Accuracy: The primary measure of success for each OCR tool, determined by how accurately the tool reads the text in each image.\n",
        "Speed: The time taken by each tool to process the images and output the text.\n",
        "Ease of Use: How simple and straightforward it was to implement each tool, considering the installation process, the complexity of the code, and the availability of documentation and support.\n",
        "Robustness: The ability of each tool to handle various challenges, such as stylized fonts, low contrast, or background noise, without significant degradation in performance.\n",
        "Tools and Environment\n",
        "The OCR tools compared in this study are EasyOCR, KerasOCR, Pytesseract, PaddleOCR, and OpenCV. All tools were tested in the same environment to ensure a fair comparison.\n",
        "\n",
        "The images were processed in their original form, with no pre-processing applied, to evaluate the raw performance of each OCR tool under typical conditions."
      ],
      "metadata": {
        "id": "sKE1oVf8vD84"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eBsXWG1fvFVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EasyOCR"
      ],
      "metadata": {
        "id": "qY3elVSjvP2A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEw1BQD8uxH9"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "\n",
        "reader = easyocr.Reader(['en'], gpu=True)\n",
        "easy_ocr_result = reader.readtext(easy_ocr_image, detail=1, paragraph = False)\n",
        "print(easy_ocr_result)\n",
        "\n",
        "for (coord, text, prob) in easy_ocr_result:\n",
        "  (top_left, top_right, bottom_right, bottom_left) = coord\n",
        "  tx, ty = (int(top_left[0]), int(top_left[1]))\n",
        "  bx, by = (int(bottom_right[0]), int(bottom_right[1]))\n",
        "  cv2.rectangle(easy_ocr_image, (tx, ty), (bx, by), (0, 255, 0), 2)\n",
        "  cv2.putText(easy_ocr_image, text, (tx, ty - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "cv2.imwrite(\"easy_ocr_result.png\", easy_ocr_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EasyOCR proved to be a reliable tool for detecting text across different types of images — whether it’s a book cover, a license plate, or a device label. Its versatility makes it a useful solution for a variety of real-world applications, from document scanning to object recognition."
      ],
      "metadata": {
        "id": "CxKx0OQgvVVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KerasOCR"
      ],
      "metadata": {
        "id": "sQcKsx6UvajA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_ocr\n",
        "\n",
        "pipeline = keras_ocr.pipeline.Pipeline() # initiliaze keras_pipeline\n",
        "\n",
        "images = [\n",
        "    keras_ocr.tools.read(img) for img in ['image.jpeg']\n",
        "]\n",
        "\n",
        "keras_ocr_result = pipeline.recognize([images[0]])\n",
        "print(keras_ocr_result)\n",
        "\n",
        "for (text, bbox) in keras_ocr_result[0]:\n",
        "  print(text)\n",
        "  print(bbox)\n",
        "  (topleft, topright, bottomright, bottomleft) = bbox\n",
        "  tx, ty = (int(topleft[0]), int(topleft[1]))\n",
        "  bx, by = (int(bottomright[0]), int(bottomright[1]))\n",
        "  cv2.rectangle(images[0], (tx, ty), (bx, by), (0, 255, 0), 2)\n",
        "  cv2.putText(images[0], text, (tx, ty - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "cv2.imwrite(\"keras_ocr_result.png\", images[0])\n",
        "sv.plot_image(images[0])"
      ],
      "metadata": {
        "id": "YNfNvL9RvgSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KerasOCR demonstrated strong performance across all three images, accurately detecting and recognizing text from different sources — a book cover, a car license plate, and a broadband router. Whether dealing with designed fonts, reflective surfaces, or curved labels, KerasOCR proved to be an efficient tool for diverse text recognition tasks."
      ],
      "metadata": {
        "id": "B6Ecxy9Wvj0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PaddleOCR"
      ],
      "metadata": {
        "id": "0jkXGPTEvpkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install paddlepaddle\n",
        "# !pip install paddleocr\n",
        "# !git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
        "\n",
        "from paddleocr import PaddleOCR, draw_ocr\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')\n",
        "\n",
        "image_vgr = cv2.imread('image.jpeg')\n",
        "text_result = ocr.ocr(image_vgr, cls=True)\n",
        "\n",
        "print(len(text_result))\n",
        "print(text_result)\n",
        "\n",
        "coordinates = []\n",
        "for data in text_result[0]:\n",
        "  for i in range(len(data)):\n",
        "    print(data[i])\n",
        "    coordinates.append(data[i])\n",
        "\n",
        "for row in text_result[0]:\n",
        "  bbox = [[int(r[0]), int(r[1])] for r in row[0]]\n",
        "  print(bbox)\n",
        "  coordinates.append(bbox)\n",
        "  cv2.putText(image_vgr, row[1][0], bbox[0], cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "cv2.imwrite(\"paddle_ocr_result.png\", image_vgr)\n",
        "sv.plot_image(image_vgr)"
      ],
      "metadata": {
        "id": "zxE-rU8ovtWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PaddleOCR is effective for detecting and recognizing text in clear, standard fonts and high-contrast environments. However, it may face challenges with stylized fonts, low contrast, complex backgrounds, and small text. Its performance can vary based on the quality and clarity of the input images."
      ],
      "metadata": {
        "id": "AaFtHp0kvxGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#pytesseract"
      ],
      "metadata": {
        "id": "F0yvU5mbvxf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import cv2\n",
        "import pytesseract\n",
        "from pytesseract import Output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image\n",
        "image_path = 'image.jpeg'  # Replace with your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert the image to grayscale\n",
        "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply thresholding to preprocess the image\n",
        "_, binary_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "# Perform text detection using Tesseract\n",
        "# If you have Tesseract installed in a custom path, specify it using:\n",
        "# pytesseract.pytesseract.tesseract_cmd = r'path_to_your_tesseract.exe'\n",
        "detection_data = pytesseract.image_to_data(binary_image, output_type=Output.DICT)\n",
        "\n",
        "# Draw the bounding boxes around detected text\n",
        "n_boxes = len(detection_data['level'])\n",
        "for i in range(n_boxes):\n",
        "    (x, y, w, h) = (detection_data['left'][i], detection_data['top'][i],\n",
        "                    detection_data['width'][i], detection_data['height'][i])\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "# Display the image with bounding boxes and detected text\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "cv2.imwrite(\"pytesseract_result.png\", cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "JoZdW94LwAJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTesseract is effective at detecting and recognizing text in clear, high-contrast images, as seen with the license plate in Image 1 and the text on the router in Image 3. However, it may struggle with more complex or stylized text, as shown in Image 1 where it has difficulty with the decorative text on the book cover; whereas it fails to detect text accurately in Image 2."
      ],
      "metadata": {
        "id": "NpggkqFXwIuh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenCV"
      ],
      "metadata": {
        "id": "ub_pyz7swJrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io as sv\n",
        "\n",
        "# Load the image\n",
        "image_path = 'image.jpeg'  # replace with your image path\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# Convert to grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Apply edge detection\n",
        "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "\n",
        "# Dilate the edges to close gaps between edge segments\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
        "dilated = cv2.dilate(edges, kernel, iterations=2)\n",
        "\n",
        "# Find contours based on edges detected\n",
        "contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Filter contours based on size, shape, etc. (assuming text is within rectangular regions)\n",
        "for contour in contours:\n",
        "    # Approximate the contour to a polygon\n",
        "    approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)\n",
        "\n",
        "    # Get bounding box for the contour\n",
        "    x, y, w, h = cv2.boundingRect(approx)\n",
        "\n",
        "    # Filter out small or large areas which are unlikely to be text\n",
        "    aspect_ratio = w / float(h)\n",
        "    if 0.2 < aspect_ratio < 5:  # Typical aspect ratio range for text\n",
        "        if 100 < w * h < 10000:  # Area constraints to filter out very small/large regions\n",
        "            # Draw bounding box around detected text area\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "# Convert image from BGR (OpenCV default) to RGB for correct color representation\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Use skimage's plot function to display the image\n",
        "sv.imshow(image_rgb)\n",
        "sv.show()\n",
        "cv2.imwrite(\"opencv_result.png\", image_rgb)"
      ],
      "metadata": {
        "id": "cyrwwCGDwNCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenCV is more effective in scenarios where the text has high contrast against a simple, uniform background, such as on license plates or printed text on plain surfaces, especially when the text is in a standard font and well-aligned. However, its effectiveness decreases in situations with complex backgrounds, varied fonts, low contrast, or when the text is surrounded by other non-text elements like patterns, logos, or images, making it harder for the algorithm to accurately isolate and identify the text."
      ],
      "metadata": {
        "id": "Vpr8XBUmwVbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "x8FIy_EIwWdw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G86inNeswRq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a04aE0Z1wEaQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}